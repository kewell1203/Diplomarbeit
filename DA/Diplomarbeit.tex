%        File: Diplomarbeit.tex
%     Created: Fri Jan 02 04:00 PM 2015 C
% Last Change: Sun Jan 12 12:00 AM 2015 C
%      Author: Eduard Zhu
%       Email: Kewell1203@gmail.com

\documentclass[a4paper, twoside, 11pt]{article}

%------------------------------%
\synctex=1
%----------- preamble ---------%
%----------- packages ---------%
\usepackage[body={15cm, 23cm}, top=4.5cm, left=4cm]{geometry}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage[perpage, symbol]{footmisc}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}

%----------- pagestyle setting ----------%
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\renewcommand{\headrulewidth}{.4pt}
\renewcommand{\footrulewidth}{.4pt}
\fancyhead[RO]{\leftmark}
\fancyhead[LE]{\rightmark}
\fancyfoot[LE, RO]{\large \thepage}

%---------- new commands ---------%
\theoremstyle{definition}
\newtheorem{definition}{DEFINITION}[section]
\newtheorem{theorem}[definition]{\large THEOREM}
\newtheorem{lemma}[definition]{\large LEMMA}
\newtheorem{proposition}[definition]{\large PROPOSITION}
\newtheorem{corollary}[definition]{\large COROLLARY}
\newtheorem{example}[definition]{\large EXAMPLE}
\renewcommand{\proofname}{\upshape\bfseries Proof.}
\renewcommand{\theequation}{\thesection.\arabic{equation}}


%---------- definitions of math -----------%
% R, N
\def\RR{$\mathcal{R}$}
\def\NN{$\mathcal{N}$}
\def\AA{$\mathscr{A}$\ }
% complement
\newcommand{\compl}[1]{{#1}^{c}}
% sigma algebra
\def\sa{$\sigma$- Algebra\ } 
% prob. space
\def\bs{$(\Omega, \mathscr{A}, \mathcal{P})$\ } 
\def\bsigma{\mathscr{B}\brkt{\mathbb{R}^{n}}}
\newcommand{\sqbr}[1]{\left[ {#1} \right]}
\newcommand{\brkt}[1]{\left({#1} \right)}

  %---------- global variables setting -----%
  \setlength{\parindent}{0em}
  \setlength{\parskip}{1.5ex plus .5ex minus .5ex}
  \renewcommand{\baselinestretch}{1.3}
  \setfnsymbol{wiley}
  \renewenvironment{abstract}{
	\begin{center}
		  \Large
		  \textbf{Abstract}
		  \hspace{2em}
	\end{center}				
  }{}

  %---------- beginning of document --------%
  \begin{document}

  %---------- title page -----------%
  \input{./title.tex}
  \newpage

  %---------- abstract -------------%
  \thispagestyle{empty}
  \begin{abstract}
	blahblah
  \end{abstract}
\newpage

%---------- contents -------------%
\thispagestyle{empty}
\mbox{}
\newpage
\fancyhead[LO, RE]{}
\fancyfoot[LE, RO]{}
\tableofcontents
\newpage
\thispagestyle{empty}
\mbox{}
\newpage

%---------- 1. introduction -------%
\fancyhead[RO]{\leftmark}
\fancyhead[LE]{\rightmark}
\fancyfoot[LE, RO]{\large \thepage}
\setcounter{section}{0}
\setcounter{page}{1}
\section{Introduction}

\newpage

%---------- 2. section ------------%
\section{Gaussian Process and Brownian Motion }
In this section we start off the general concept of probability spaces and stochastic processes. Of this, a most important case we then discribe, is Gaussian process. It bring us to introduce the Brownian Motion as a fine example.

%---------- 2.1. subsection -------%
\subsection{Probability Space and Stochastic Process }
\begin{definition}
  Let \AA be a collection of subsets of a set $\Omega$. \AA is then a \emph{$\sigma$- Algebra} on $\Omega$ if it satisfies the following conditions:
  \begin{enumerate}[topsep=0pt, itemsep=-1ex, partopsep=1ex, parsep=1ex, label=(\roman*)]
	\item $\Omega \in $ \AA.
	\item For any set $F \in \mathscr{A}$, its complement $\compl{F} \in$ \AA.
	\item If a serie $\{F_n\}_{n \in \mathbb{N}} \subseteq \mathscr{A}$, then $\cup_{n \in \mathbb{N}}F_n \in $ \AA.
  \end{enumerate}
\end{definition}

\begin{definition}
  A mapping $\mathcal{P}$ is said to be a \emph{probability measure} from $\mathscr{A}$ to $\bsigma$, if $\mathcal{P}\sqbr{\sum_{n=1}^{\infty} F_n} = \sum_{n=1}^{\infty} \mathcal{P}\sqbr{F_n}$ for any $\{F_n\}_{n \in \mathbb{N}}$ disjoint in $\mathscr{A}$ satisfying $\sum_{n=1}^{\infty}F_n \in \mathscr{A}$. 
\end{definition}

\begin{definition}
  A \emph{probability space} is defined as a triple \bs of a set $\Omega$, a \sa \AA  of $\Omega$ and a measure $\mathcal{P}$ from $\mathscr{A}$ to $\bsigma$.
\end{definition}

The $\sigma$- Algebra generated of all open sets on $\mathbb{R}^{n}$ is called the \emph{Borel $\sigma$- Algebra} which we denote as usual by $\mathscr{B}\left(\mathbb{R}^{n}\right)$. Let $\mu$ be a probability measure on $\mathbb{R}^{n}$. Indeed, $\brkt{\mathbb{R}^{n}, \mathscr{B}\brkt{\mathbb{R}^{n}}, \mu}$ is a special case that probability space on $\mathbb{R}^{n}$. A function $f$ mapping from $\brkt{\mathcal{D}, \mathscr{D}, \mu}$ into $\brkt{\mathcal{E}, \mathscr{E}, \nu}$ is \emph{measurable} if its collection of the inverse image of $\mathscr{E}$ is a subset of $\mathscr{D}$. A \emph{random variable} is a $\mathbb{R}^{n}$-valued measurable function on some probability space. Let $\mathcal{P}$ represent a probability measure, recall that in probability theory, for $B \in \bsigma$ we call $\mathcal{P}\sqbr{\left\{X \in B\right\}}$ the \emph{distribution} of $X$. We write also $\mathcal{P}_X \sqbr{\cdot}$ or $\mathcal{P}\sqbr{X}$ for convenience of the notation above.

\begin{definition}
  Let $\brkt{\Omega, \mathscr{A}, \mathcal{P}}$ be a probability space. A $n$-dimensional \emph{stochastic process} $\brkt{X_t}$ is a family of random variable such that $X_t\brkt{\omega} : \Omega \longrightarrow  \mathbb{R}^{n},  \forall t \in T$, where $T$ denotes the set of Index of Time.    
\end{definition}

\begin{definition}
  A stochastic process $\brkt{X_t}_{t \in T}$ is said to be \emph{stationary}, if the joint distribution 
\[
  \mathcal{P}\sqbr{X_{t_1},\dots,X_{t_n}} = \mathcal{P}\sqbr{X_{t_1+\tau},\dots,X_{t_n+\tau}} 
\]
for $t_1, \dots, t_n$ and $t_1+\tau,\dots,t_n+\tau \in T$. 
\label{sec:stn}
\end{definition}

Remark that, definition \ref{sec:stn} means the distribution of a stationary process is independent of a shift of time.

%---------- 2.2. subsection -------%
\subsection{Definition of Gaussian Process}
\begin{definition}[1-dimensional normal distribution]
  A $\mathbb{R}$-valued random variable $X$ is said to be \emph{standard normal distributed}, if its distribution can be discribed as
  \[
	\mathcal{P}\sqbr{X \le x} = \int_{-\infty}^{x} (2\pi)^{-\frac{1}{2}}e^{-\frac{u^2}{2}}\,\mathop{du}  
  \]
  for $x \in \mathbb{R}$.
\end{definition}

\begin{definition}
  A $\mathbb{R}$-valued random variable $X$ is said to be \emph{normal distributed} with a \emph{mean} $\mu$ and a \emph{variance} $\sigma^2$, if
\[
  (X-\mu) / \sigma
\]
is standard normal distributed.
\end{definition}

We use a notation $X \sim Y$, which means $X$ and $Y$ have the same distribution. In similar way it is denoted by $X \sim (2\pi)^{-\frac{1}{2}}e^{-\frac{x^2}{2}}\mathop{dx} $, if it is standard normal distributed. In order to identifing the behaviour of a normal distributed random variable we recall the characteristic function in probability theory, see\cite{bauer}. 

\begin{proposition}
  Let $X$ be a $\mathbb{R}$-valued standard normal distributed random variable. The characteristic function of $X$
\begin{equation}
  \Psi_X(\xi) := \int_\mathbb{R} e^{ix\xi}\mathcal{P}\sqbr{X \in \mathop{dx}} = e^{-\frac{\xi^2}{2}}
  \label{sec:cht}
\end{equation}
for $\xi \in \mathbb{R}$.
\end{proposition}
\begin{proof}
  According the definion of characteristic function
  \begin{equation*}
	\Psi_X(\xi) = \int_\mathbb{R} (2\pi)^{-\frac{1}{2}}e^{-\frac{x^2}{2}}e^{ix\xi}\,\mathop{dx},
  \end{equation*}
take differentiating both sides of the equation by $\xi$, then
\begin{eqnarray*}
\Psi_X'(\xi) &=& \int_\mathbb{R}(2\pi)^{-\frac{1}{2}}e^{-\frac{x^2}{2}}e^{ix\xi}ix\,\mathop{dx}\\
             &=& (-i)\cdot\int_\mathbb{R} (2\pi)^{-\frac{1}{2}}(\frac{d}{dx}e^{-\frac{x^2}{2}})e^{ix\xi}\,\mathop{dx}\\
			 &\overset{part.int.}{=}& -\int_\mathbb{R}(2\pi)^{-\frac{1}{2}}e^{-\frac{x^2}{2}}e^{ix\xi}\xi\,\mathop{dx}\\
			 &=& -\xi\Psi_X(\xi).
\end{eqnarray*}
Obviously, 
$\Psi(\xi) = \Psi(0)e^{-\frac{\xi^2}{2}}$ is the solution of the partial differential equation above, and $\Psi(0)$ is equal to $1$.
\end{proof}

In particular, the characteristic function of a normal distributed random variable with a mean $\mu$ and a variance $\sigma^2$, which denoted by $\Psi_{X_{\mu,\sigma^2}}(\xi)$, is $e^{i\mu\xi-\frac{1}{2}(\sigma\xi)^2}$. To achieve this result, we just need to substitute $x$ by $(x-\mu)/\sigma$ in the calculation before. 

\begin{definition}
  Let $X$ be a $\mathbb{R}^{n}$-valued random variable. $X$ is said to be \emph{normal distributed}, if for any $d \in \mathbb{R}^{n}$ such that $d^TX$ is normal distributed on $\mathbb{R}$.
\end{definition}
%Note that, $<d,X>$ is defined as scalar product on $\mathbb{R}^{n}$ that means $\sum_{j=1}^{n}\,d_j\cdot X_i$. 
\begin{proposition}
  Let $X$ be a $\mathbb{R}^{n}$-valued normal distributed. Then there exist $m \in \mathbb{R}^{n}$ and a positive definite symmetric matrix $\Sigma \in \mathbb{R}^{n\times n}$ such that,
  \begin{equation}
	\mathrm{E}\,e^{i\xi^TX} = e^{i\xi^Tm - \frac{1}{2}\xi^T \Sigma \xi}
	\label{sec:mcf}
  \end{equation}
  For $\xi \in \mathbb{R}^{n}$. Furthermore, the density function of $X$ is
\begin{equation}
  (2\pi)^{-\frac{d}{2}}\, (\det\Sigma) ^{-\frac{1}{2}}\,e^{-\frac{1}{2}(x-m)^T\Sigma^{-1}(x-m)}\,\mathop{dx}.
  \label{sec:dsy}
\end{equation}
\end{proposition}

Remark, the equation (\ref{sec:mcf}) can also be as definition of characteristic function of a n-dimensional normal distributed random variable.

\begin{proof}
  Since $X$ normal distributed on $\mathbb{R}^{n}$, then $\xi^T X$ is normal distributed on $\mathbb{R}$. Due to the proposition 2.8 there is
  \begin{eqnarray*}
	\mathrm{E} e^{i\xi^T X} &=& \mathrm{E} e^{i\cdot 1 \cdot \xi^T X}\\
	                        &=& e^{i\mathrm{E}\sqbr{\xi^T X} -\frac{1}{2}\mathrm{Var}\sqbr{\xi^T X}}\\
							&=& e^{i\xi^T\mathrm{E}\sqbr{X} - \frac{1}{2}\xi^T \mathrm{Var}\sqbr{X} \xi}.
	\label{}
  \end{eqnarray*}
  According the uniqueness theorem of characteristic function (Satz 23.4 in \cite{bauer}), then we can deduce the density function of the equation (\ref{sec:dsy}).
\end{proof}

A normal distributed normal random variable can be characterized by its mean and variance respectively mean vector and covariance vector because of the characteristic function.

\begin{definition}
  Let $(X_t)_{t \in T}$ be a $\mathbb{R}^{n}$-valued stochastic process. $(X_t)$ is said to be a \emph{gaussian process} if 
  \[
	c_1^TX_{t_1} + \cdots + c_n^TX_{t_n} 
  \]
  has a normal distribution for any $c_1 \cdots c_n \in \mathbb{R}^{n}$, $t_1 \dots t_n \in T$ and $n \in \mathbb{N}$. 
\end{definition}
The definition immediately shows for every $X_t$ in gaussian process has a distribution.

\newpage

%---------- 3. section ------------%
\section{Fractional Brownian Motion}

\newpage

%---------- 4. section ------------%
\section{Fractional Ornstein Uhlenbeck Process Model}

\newpage

%---------- 5. Anwendung in die finanzmathe bzw. in der volatility process -------%
\section{Application in Financial Mathematics}

\newpage

%---------- x. conclusion ---------%
\section{Conclusion}

\newpage

%---------- reference -------------%
\addcontentsline{toc}{section}{References}
\fancyhead[LO, RE]{}
\begin{thebibliography}{99}
	\bibitem{bauer} \textsc{Bauer,~H.} (2002). Wahrscheinlichkeitstheorie(5th. durchges. und verb. Aufl.). Berlin: W. de Gruyter

\end{thebibliography}
\newpage
\end{document}


